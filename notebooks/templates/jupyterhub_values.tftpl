# JupyterHub Helm values with Keycloak SSO integration

hub:
  resources:
    requests:
      cpu: "${hub_resources.requests.cpu}"
      memory: "${hub_resources.requests.memory}"
    limits:
      cpu: "${hub_resources.limits.cpu}"
      memory: "${hub_resources.limits.memory}"
  config:
    JupyterHub:
      authenticator_class: generic-oauth
    GenericOAuthenticator:
      oauth_callback_url: "https://${jupyterhub_host}/hub/oauth_callback"
      authorize_url: "${keycloak_auth_url}"
      token_url: "${keycloak_token_url}"
      userdata_url: "${keycloak_userinfo_url}"
      login_service: "Keycloak"
      username_claim: "preferred_username"
      claim_groups_key: "groups"
      allowed_groups:
        - "jupyterhub-admins"
        - "jupyterhub-users"
      admin_groups:
        - "jupyterhub-admins"
      scope:
        - "openid"
        - "profile"
        - "email"
        - "groups"
  extraEnv:
    - name: OAUTH_CLIENT_ID
      valueFrom:
        secretKeyRef:
          name: ${oauth_secret_name}
          key: client_id
    - name: OAUTH_CLIENT_SECRET
      valueFrom:
        secretKeyRef:
          name: ${oauth_secret_name}
          key: client_secret
  extraConfig:
    spawner: |
      c.KubeSpawner.cmd = ['jupyterhub-singleuser']
    oauth-secrets: |
      import os
      c.GenericOAuthenticator.client_id = os.environ['OAUTH_CLIENT_ID']
      c.GenericOAuthenticator.client_secret = os.environ['OAUTH_CLIENT_SECRET']

singleuser:
  image:
    name: "${singleuser_image_name}"
    tag: "${singleuser_image_tag}"
  cpu:
    limit: ${singleuser_cpu_limit}
    guarantee: 0.5
  memory:
    limit: ${singleuser_memory_limit_bytes}
    guarantee: 1G
  storage:
    type: dynamic
    capacity: "${storage_size_gb}Gi"
    dynamic:
      storageClass: null
      pvcNameTemplate: "claim-{username}"
      volumeNameTemplate: "volume-{username}"
      storageAccessModes:
        - ReadWriteOnce
    extraVolumeMounts:
      - name: examples
        mountPath: /home/jovyan/examples
        readOnly: true
    extraVolumes:
      - name: examples
        configMap:
          name: jupyterhub-examples
  extraEnv:
    NESSIE_URI: "${nessie_uri}"
    TRINO_HOST: "${trino_host}"
    TRINO_PORT: "${trino_port}"
    # PyIceberg default catalog configuration
    PYICEBERG_CATALOG__DEFAULT__TYPE: "rest"
    PYICEBERG_CATALOG__DEFAULT__URI: "${nessie_uri}"
    # Remote signing configuration (keeps credentials secure on Nessie side)
    PYICEBERG_CATALOG__DEFAULT__HEADER__X-ICEBERG-ACCESS-DELEGATION: "remote-signing"
    PYICEBERG_CATALOG__DEFAULT__S3__SIGNER: "S3V4RestSigner"
    PYICEBERG_CATALOG__DEFAULT__S3__SIGNER__URI: "${nessie_uri}"
    PYICEBERG_CATALOG__DEFAULT__S3__SIGNER__ENDPOINT: "v1/aws/s3/sign"
    PYICEBERG_CATALOG__DEFAULT__PY-IO-IMPL: "pyiceberg.io.fsspec.FsspecFileIO"
  lifecycleHooks:
    postStart:
      exec:
        command:
          - "sh"
          - "-c"
          - |
            pip install --no-cache-dir --quiet \
              "polars>=1.0.0" \
              "pyarrow>=15.0.0" \
              "pyiceberg[s3fs,pyarrow]>=0.7.0" \
              "s3fs>=2024.2.0" \
              "boto3" \
              "trino" \
              "duckdb" \
              "httpx" \
              "plotly" \
              "altair"

cull:
  enabled: true
  timeout: 3600
  every: 300
  concurrency: 10
  maxAge: 0

proxy:
  chp:
    resources:
      requests:
        cpu: "${proxy_resources.requests.cpu}"
        memory: "${proxy_resources.requests.memory}"
      limits:
        cpu: "${proxy_resources.limits.cpu}"
        memory: "${proxy_resources.limits.memory}"
  service:
    type: ClusterIP

scheduling:
  userScheduler:
    enabled: false
  userPlaceholder:
    enabled: false

prePuller:
  hook:
    enabled: false
  continuous:
    enabled: false
