{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with PyIceberg + Polars\n",
    "\n",
    "This notebook demonstrates how to query Iceberg tables managed by Nessie using PyIceberg and analyze the data with Polars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the required libraries and configure our connection to the Nessie catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
    "source": "import os\nimport polars as pl\nfrom IPython.display import display\nfrom pyiceberg.catalog import load_catalog\n\n# Configuration from environment variables\n# S3 credentials are managed server-side by Nessie\nNESSIE_URI = os.environ.get(\"NESSIE_URI\", \"http://nessie.agartha-catalog.svc.cluster.local:19120/iceberg\")\nTRINO_HOST = os.environ.get(\"TRINO_HOST\", \"trino.agartha-processing-trino.svc.cluster.local\")\nTRINO_PORT = int(os.environ.get(\"TRINO_PORT\", \"8080\"))\n\nprint(f\"Nessie URI: {NESSIE_URI}\")\nprint(f\"Trino: {TRINO_HOST}:{TRINO_PORT}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Nessie Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
    "source": "# Connect using Nessie's Iceberg REST catalog\n# S3 credentials are configured server-side with remote signing\ncatalog = load_catalog(\n    \"nessie\",\n    type=\"rest\",\n    uri=NESSIE_URI,\n    **{\n        \"header.X-Iceberg-Access-Delegation\": \"remote-signing\",\n        \"s3.signer\": \"S3V4RestSigner\",\n        \"s3.signer.uri\": NESSIE_URI,\n        \"s3.signer.endpoint\": \"v1/aws/s3/sign\",\n        \"py-io-impl\": \"pyiceberg.io.fsspec.FsspecFileIO\",\n    }\n)\n\nprint(\"Connected to Nessie catalog!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Available Namespaces and Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List namespaces\n",
    "namespaces = catalog.list_namespaces()\n",
    "print(\"Available namespaces:\")\n",
    "for ns in namespaces:\n",
    "    print(f\"  - {ns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List tables in each namespace\n",
    "for ns in namespaces:\n",
    "    tables = catalog.list_tables(ns)\n",
    "    if tables:\n",
    "        print(f\"\\nTables in {ns}:\")\n",
    "        for table in tables:\n",
    "            print(f\"  - {table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an Iceberg Table into Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GitHub repositories table (adjust table name as needed)\n",
    "try:\n",
    "    table = catalog.load_table(\"raw.github_repositories\")\n",
    "    print(f\"Table: {table.name()}\")\n",
    "    print(f\"\\nSchema:\")\n",
    "    print(table.schema())\n",
    "except Exception as e:\n",
    "    print(f\"Could not load table: {e}\")\n",
    "    print(\"Make sure the table exists by running the Dagster pipeline first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan the table and convert to Polars DataFrame\n",
    "try:\n",
    "    arrow_table = table.scan().to_arrow()\n",
    "    df = pl.from_arrow(arrow_table)\n",
    "    print(f\"Loaded {len(df)} rows\")\n",
    "    df.head(10)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Data with Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
      "source": [
      "# Example: Group by language and compute statistics\n",
      "try:\n",
      "    language_stats = (\n",
      "        df.group_by(\"language\")\n",
      "        .agg([\n",
      "            pl.len().alias(\"repo_count\"),\n",
      "            pl.col(\"stargazers_count\").sum().alias(\"total_stars\"),\n",
      "            pl.col(\"forks_count\").sum().alias(\"total_forks\"),\n",
      "        ])\n",
      "        .sort(\"total_stars\", descending=True)\n",
      "    )\n",
      "    display(language_stats)\n",
      "except Exception as e:\n",
      "    print(f\"Error: {e}\")"
     ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query with Column Selection and Filtering\n",
    "\n",
    "PyIceberg supports predicate pushdown for efficient queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select specific columns and filter\n",
    "try:\n",
    "    # Only fetch specific columns (projection pushdown)\n",
    "    scan = table.scan(\n",
    "        selected_fields=(\"name\", \"language\", \"stargazers_count\", \"forks_count\")\n",
    "    )\n",
    "    \n",
    "    df_subset = pl.from_arrow(scan.to_arrow())\n",
    "    \n",
    "    # Filter in Polars for repos with > 100 stars\n",
    "    popular_repos = df_subset.filter(pl.col(\"stargazers_count\") > 100)\n",
    "    print(f\"Repos with > 100 stars: {len(popular_repos)}\")\n",
    "    popular_repos.head(10)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Query via Trino\n",
    "\n",
    "You can also query tables through Trino for more complex SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from trino.dbapi import connect\n\ntry:\n    conn = connect(\n        host=TRINO_HOST,\n        port=TRINO_PORT,\n        user=\"jupyter\",\n        catalog=\"agartha\",\n        schema=\"raw\",\n    )\n    \n    cursor = conn.cursor()\n    cursor.execute(\"SHOW TABLES\")\n    tables = cursor.fetchall()\n    print(\"Tables available via Trino:\")\n    for t in tables:\n        print(f\"  - {t[0]}\")\nexcept Exception as e:\n    print(f\"Could not connect to Trino: {e}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
     "source": [
     "# Query via Trino and load into Polars\n",
     "try:\n",
     "    cursor.execute(\"\"\"\n",
     "        SELECT language, COUNT(*) as repo_count, SUM(stargazers_count) as total_stars\n",
     "        FROM raw.github_repositories\n",
     "        GROUP BY language\n",
     "        ORDER BY total_stars DESC\n",
     "        LIMIT 10\n",
     "    \"\"\")\n",
     "    \n",
     "    rows = cursor.fetchall()\n",
     "    columns = [desc[0] for desc in cursor.description]\n",
     "    \n",
     "    df_trino = pl.DataFrame(rows, schema=columns, orient=\"row\")\n",
     "    df_trino.show()\n",
     "except Exception as e:\n",
     "    print(f\"Error: {e}\")"
    ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}